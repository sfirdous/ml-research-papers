{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "rgSotYffaaIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"MICCAI_BraTS2020_TrainingData\"\n",
        "TARGET_SIZE = (64, 64)\n",
        "\n",
        "# List to hold all processed 3-channel image samples\n",
        "all_images = []\n",
        "# List to hold the binary labels (0 or 1)\n",
        "all_labels = []"
      ],
      "metadata": {
        "id": "kUiXSXCOadGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Function for Normalization\n",
        "def normalize_slice(slice_data):\n",
        "    if np.std(slice_data) == 0:\n",
        "        return slice_data # Skip normalization if standard deviation is zero\n",
        "    mean = np.mean(slice_data)\n",
        "    std = np.std(slice_data)\n",
        "    # Add a small epsilon to prevent division by zero in case of unexpected data\n",
        "    return (slice_data - mean) / (std + 1e-8)"
      ],
      "metadata": {
        "id": "A8L932CTahU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Data Processing Loop\n",
        "\n",
        "# Iterate over every patient folder in the dataset directory\n",
        "for patient_folder in os.listdir(DATA_PATH):\n",
        "    # Construct the full path to the patient's directory\n",
        "    patient_dir = os.path.join(DATA_PATH, patient_folder)\n",
        "\n",
        "    # Skip any files that are not directories\n",
        "    if not os.path.isdir(patient_dir):\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # --- Step 1: Load Raw 3D Volumes ---\n",
        "        # We select three modalities (T1, T1ce, FLAIR) for the 3 channels\n",
        "        # T1c is often the best for tumor boundaries, FLAIR for edema\n",
        "\n",
        "        # NOTE: File naming convention might vary. Adjust if your file names are different.\n",
        "        files = {\n",
        "            'T1': nib.load(os.path.join(patient_dir, patient_folder + '_t1.nii.gz')).get_fdata(),\n",
        "            'T1ce': nib.load(os.path.join(patient_dir, patient_folder + '_t1ce.nii.gz')).get_fdata(),\n",
        "            'FLAIR': nib.load(os.path.join(patient_dir, patient_folder + '_flair.nii.gz')).get_fdata(),\n",
        "            'SEG': nib.load(os.path.join(patient_dir, patient_folder + '_seg.nii.gz')).get_fdata() # Segmentation for labels\n",
        "        }\n",
        "\n",
        "        # Ensure all volumes are the same shape (a standard BRATS assumption)\n",
        "        num_slices = files['T1'].shape[2]\n",
        "\n",
        "        # Step 2 & 3: Slice Extraction, Normalization, Resizing, and Stacking\n",
        "\n",
        "        # Iterate through every slice (Z-axis)\n",
        "        for z in range(num_slices):\n",
        "\n",
        "            # Extract 2D slices for all 4 volumes\n",
        "            slice_T1 = files['T1'][:, :, z]\n",
        "            slice_T1ce = files['T1ce'][:, :, z]\n",
        "            slice_FLAIR = files['FLAIR'][:, :, z]\n",
        "            slice_SEG = files['SEG'][:, :, z]\n",
        "\n",
        "            # --- Filter Blank Slices ---\n",
        "            # Use the T1ce slice to check for any brain matter (non-zero value)\n",
        "            if np.max(slice_T1ce) > 0:\n",
        "\n",
        "                # --- Step 3 (cont.): Normalization ---\n",
        "                norm_T1 = normalize_slice(slice_T1)\n",
        "                norm_T1ce = normalize_slice(slice_T1ce)\n",
        "                norm_FLAIR = normalize_slice(slice_FLAIR)\n",
        "\n",
        "                # --- Step 4: Resize and Stack (64x64x3) ---\n",
        "\n",
        "                # Resize each channel independently\n",
        "                # We use resize(..., preserve_range=True) to keep normalized values\n",
        "                resized_T1 = resize(norm_T1, TARGET_SIZE, anti_aliasing=True, preserve_range=True)\n",
        "                resized_T1ce = resize(norm_T1ce, TARGET_SIZE, anti_aliasing=True, preserve_range=True)\n",
        "                resized_FLAIR = resize(norm_FLAIR, TARGET_SIZE, anti_aliasing=True, preserve_range=True)\n",
        "\n",
        "                # Stack the three 2D arrays to create the 3-channel input tensor (64, 64, 3)\n",
        "                three_channel_tensor = np.stack(\n",
        "                    [resized_T1, resized_T1ce, resized_FLAIR],\n",
        "                    axis=-1 # Stacks along the last axis, creating the channel dimension\n",
        "                )\n",
        "\n",
        "                # --- Labeling (Binary Classification) ---\n",
        "                # Label is 1 if any segmentation value is > 0 (tumor present)\n",
        "                label = 1 if np.max(slice_SEG) > 0 else 0\n",
        "\n",
        "                # Append the processed sample and its label to the master lists\n",
        "                all_images.append(three_channel_tensor)\n",
        "                all_labels.append(label)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing patient {patient_folder}: {e}\")\n",
        "        continue\n",
        "\n",
        "print(f\"\\nTotal number of image slices extracted: {len(all_images)}\")\n",
        "\n",
        "# Convert lists to final NumPy arrays for training\n",
        "X = np.array(all_images, dtype=np.float32)\n",
        "Y = np.array(all_labels, dtype=np.int32)\n",
        "\n",
        "print(f\"Final Input Data (X) Shape: {X.shape}\") # Expected: (N, 64, 64, 3)\n",
        "print(f\"Final Label Data (Y) Shape: {Y.shape}\") # Expected: (N,)"
      ],
      "metadata": {
        "id": "bi9iglZdaqhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxH3Xks07JiD"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- Step 5: Train/Test Split (80:20 Ratio from the Paper) ---\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y,\n",
        "    test_size=0.20,             # 20% for testing\n",
        "    random_state=42,            # Ensures the split is the same every time\n",
        "    stratify=Y                  # Keeps the ratio of tumor/no-tumor slices equal in train/test sets\n",
        ")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"Data Split Complete.\")\n",
        "print(f\"Training Set Shape (X_train): {X_train.shape}\")\n",
        "print(f\"Testing Set Shape (X_test): {X_test.shape}\")\n",
        "print(\"-\" * 50)"
      ]
    }
  ]
}